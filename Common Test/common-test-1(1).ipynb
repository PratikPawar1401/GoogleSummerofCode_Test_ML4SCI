{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11143405,"sourceType":"datasetVersion","datasetId":6951249}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    accuracy_score, \n    roc_auc_score, \n    roc_curve, \n    confusion_matrix,\n    classification_report\n)\nfrom sklearn.preprocessing import label_binarize\nimport timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:40:06.889882Z","iopub.execute_input":"2025-03-29T13:40:06.890318Z","iopub.status.idle":"2025-03-29T13:40:06.895429Z","shell.execute_reply.started":"2025-03-29T13:40:06.890286Z","shell.execute_reply":"2025-03-29T13:40:06.894744Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class DeepLensConfig:\n    \"\"\"Centralized configuration management\"\"\"\n    def __init__(self):\n        # Model Hyperparameters\n        self.lr = 1e-4\n        self.batch_size = 64\n        self.num_classes = 3\n        self.epochs = 10\n        self.weight_decay = 1e-2\n        \n        # Model Architecture\n        self.model_name = \"resnet18\"\n        self.pretrained = True\n        \n        # Training Settings\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.num_workers = 4\n        self.seed = 42\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:40:06.896586Z","iopub.execute_input":"2025-03-29T13:40:06.896797Z","iopub.status.idle":"2025-03-29T13:40:06.913901Z","shell.execute_reply.started":"2025-03-29T13:40:06.896778Z","shell.execute_reply":"2025-03-29T13:40:06.913113Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class LensDataset(Dataset):\n    \"\"\"Custom Dataset for Lens Classification\"\"\"\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        image_path = self.dataframe['data_path'].iloc[idx]\n        image = np.load(image_path).astype(np.float32)\n        \n        # Ensure the image is 2D (single channel)\n        if image.ndim == 3:\n            image = image.squeeze()\n        \n        label = self.dataframe['target'].iloc[idx]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        \n        # Ensure the tensor is 3D: [1, height, width]\n        return torch.tensor(image).unsqueeze(0), torch.tensor(label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:40:06.915562Z","iopub.execute_input":"2025-03-29T13:40:06.915756Z","iopub.status.idle":"2025-03-29T13:40:06.932817Z","shell.execute_reply.started":"2025-03-29T13:40:06.915740Z","shell.execute_reply":"2025-03-29T13:40:06.932139Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class LensClassificationModel(nn.Module):\n    \"\"\"Lens Classification Model using Pretrained Architecture\"\"\"\n    def __init__(self, config):\n        super().__init__()\n        self.model = timm.create_model(\n            config.model_name, \n            pretrained=config.pretrained, \n            in_chans=1\n        )\n        \n        # Modify classifier\n        classifier_name = self.model.default_cfg['classifier']\n        n_features = self.model._modules[classifier_name].in_features\n        self.model._modules[classifier_name] = nn.Identity()\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(n_features, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(512, config.num_classes)\n        )\n\n    def forward(self, x):\n        features = self.model(x)\n        return self.classifier(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:40:06.933797Z","iopub.execute_input":"2025-03-29T13:40:06.934092Z","iopub.status.idle":"2025-03-29T13:40:06.948679Z","shell.execute_reply.started":"2025-03-29T13:40:06.934066Z","shell.execute_reply":"2025-03-29T13:40:06.947882Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class ModelTrainer:\n    \"\"\"Comprehensive Training and Evaluation Pipeline\"\"\"\n    def __init__(self, config):\n        self.config = config\n        self.device = config.device\n        \n    def prepare_data(self, data_dir):\n        \"\"\"Prepare training and validation datasets\"\"\"\n        def _get_image_paths(base_path, classes):\n            paths = []\n            labels = []\n            for label, cls in enumerate(classes):\n                class_path = os.path.join(base_path, cls)\n                for img_file in os.listdir(class_path):\n                    paths.append(os.path.join(class_path, img_file))\n                    labels.append(label)\n            return paths, labels\n\n        # Assuming directory structure: data_dir/train/(no/sphere/vort)\n        train_path = os.path.join(data_dir, 'train')\n        classes = ['no', 'sphere', 'vort']\n        \n        paths, labels = _get_image_paths(train_path, classes)\n        \n        df = pd.DataFrame({\n            'data_path': paths,\n            'target': labels\n        })\n        \n        # Split into train and validation\n        train_df, val_df = train_test_split(\n            df,\n            # 90 : 10 split\n            test_size=0.1, \n            stratify=df['target'], \n            random_state=self.config.seed\n        )\n        \n        return train_df, val_df\n\n    def create_dataloaders(self, train_df, val_df):\n        \"\"\"Create PyTorch DataLoaders\"\"\"\n        train_dataset = LensDataset(train_df)\n        val_dataset = LensDataset(val_df)\n        \n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=self.config.batch_size, \n            shuffle=True, \n            num_workers=self.config.num_workers\n        )\n        \n        val_loader = DataLoader(\n            val_dataset, \n            batch_size=self.config.batch_size, \n            shuffle=False, \n            num_workers=self.config.num_workers\n        )\n        \n        return train_loader, val_loader\n\n    def train(self, train_loader, val_loader):\n        \"\"\"Main training loop with comprehensive logging\"\"\"\n        model = LensClassificationModel(self.config).to(self.device)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(\n            model.parameters(), \n            lr=self.config.lr, \n            weight_decay=self.config.weight_decay\n        )\n        \n        best_val_auc = 0\n        training_history = {\n            'train_loss': [],\n            'val_loss': [],\n            'val_auc': []\n        }\n        \n        for epoch in range(self.config.epochs):\n            # Training Phase\n            model.train()\n            train_losses = []\n            \n            for images, labels in train_loader:\n                images, labels = images.to(self.device), labels.to(self.device)\n                \n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                \n                train_losses.append(loss.item())\n            \n            # Validation Phase\n            model.eval()\n            val_losses = []\n            all_preds = []\n            all_labels = []\n            \n            with torch.no_grad():\n                for images, labels in val_loader:\n                    images, labels = images.to(self.device), labels.to(self.device)\n                    outputs = model(images)\n                    loss = criterion(outputs, labels)\n                    \n                    val_losses.append(loss.item())\n                    preds = torch.softmax(outputs, dim=1)\n                    all_preds.append(preds.cpu().numpy())\n                    all_labels.append(labels.cpu().numpy())\n            \n            # Aggregate predictions and labels\n            all_preds = np.concatenate(all_preds)\n            all_labels = np.concatenate(all_labels)\n            \n            # Calculate metrics\n            val_auc = roc_auc_score(all_labels, all_preds, multi_class='ovr')\n            \n            # Log metrics\n            avg_train_loss = np.mean(train_losses)\n            avg_val_loss = np.mean(val_losses)\n            \n            training_history['train_loss'].append(avg_train_loss)\n            training_history['val_loss'].append(avg_val_loss)\n            training_history['val_auc'].append(val_auc)\n            \n            # Print epoch summary\n            print(f\"Epoch {epoch+1}/{self.config.epochs}\")\n            print(f\"Train Loss: {avg_train_loss:.4f}\")\n            print(f\"Val Loss: {avg_val_loss:.4f}\")\n            print(f\"Val AUC: {val_auc:.4f}\")\n            \n            # Model checkpoint\n            if val_auc > best_val_auc:\n                best_val_auc = val_auc\n                torch.save({\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'best_val_auc': best_val_auc\n                }, 'best_model.pth')\n        \n        return model, all_preds, all_labels, training_history\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:40:06.949352Z","iopub.execute_input":"2025-03-29T13:40:06.949609Z","iopub.status.idle":"2025-03-29T13:40:06.963663Z","shell.execute_reply.started":"2025-03-29T13:40:06.949590Z","shell.execute_reply":"2025-03-29T13:40:06.963056Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class ModelVisualizer:\n    \"\"\"Visualization utilities for model performance\"\"\"\n    @staticmethod\n    def plot_training_history(history, save_path='training_history.png'):\n        \"\"\"Plot training and validation loss/AUC\"\"\"\n        plt.figure(figsize=(12, 4))\n        \n        # Loss Plot\n        plt.subplot(1, 2, 1)\n        plt.plot(history['train_loss'], label='Train Loss')\n        plt.plot(history['val_loss'], label='Validation Loss')\n        plt.title('Training and Validation Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        \n        # AUC Plot\n        plt.subplot(1, 2, 2)\n        plt.plot(history['val_auc'], label='Validation AUC', color='green')\n        plt.title('Validation AUC')\n        plt.xlabel('Epoch')\n        plt.ylabel('AUC Score')\n        plt.legend()\n        \n        plt.tight_layout()\n        plt.savefig(save_path)\n        plt.close()\n\n    @staticmethod\n    def plot_confusion_matrix(labels, predictions, class_names, save_path='confusion_matrix.png'):\n        \"\"\"Create and save confusion matrix visualization\"\"\"\n        # Get predicted class labels\n        pred_labels = np.argmax(predictions, axis=1)\n        \n        # Compute confusion matrix\n        cm = confusion_matrix(labels, pred_labels)\n        \n        plt.figure(figsize=(8, 6))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                    xticklabels=class_names, \n                    yticklabels=class_names)\n        plt.title('Confusion Matrix')\n        plt.xlabel('Predicted Label')\n        plt.ylabel('True Label')\n        plt.tight_layout()\n        plt.savefig(save_path)\n        plt.close()\n\n    @staticmethod\n    def plot_roc_curve(labels, predictions, class_names, save_path='roc_curve.png'):\n        \"\"\"Plot ROC curves for multiclass classification\"\"\"\n        plt.figure(figsize=(10, 8))\n        \n        # One-vs-Rest ROC Curves\n        for i in range(len(class_names)):\n            # Create binary labels for current class\n            binary_labels = (labels == i).astype(int)\n            class_preds = predictions[:, i]\n            \n            # Compute ROC curve\n            fpr, tpr, _ = roc_curve(binary_labels, class_preds)\n            \n            # Calculate AUC\n            roc_auc = roc_auc_score(binary_labels, class_preds)\n            \n            # Plot ROC curve\n            plt.plot(fpr, tpr, \n                     label=f'ROC curve (class: {class_names[i]}, AUC = {roc_auc:.2f})')\n        \n        plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver Operating Characteristic (ROC) Curve')\n        plt.legend(loc=\"lower right\")\n        plt.tight_layout()\n        plt.savefig(save_path)\n        plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:40:07.007832Z","iopub.execute_input":"2025-03-29T13:40:07.008064Z","iopub.status.idle":"2025-03-29T13:40:07.016424Z","shell.execute_reply.started":"2025-03-29T13:40:07.008044Z","shell.execute_reply":"2025-03-29T13:40:07.015762Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def main():\n    # Configuration\n    config_class = DeepLensConfig\n    data_dir = '/kaggle/input/commontest/dataset'\n    \n    # Define classes explicitly\n    CLASS_NAMES = ['no', 'sphere', 'vort']\n\n    \n\n    # MANUAL PARAMETER INPUT\n\n    BEST_PARAMS = {\n        'lr': 0.0007166,          # Learning rate\n        'batch_size': 32,          # Batch size\n        'weight_decay': 0.0002875, # Weight decay\n        'model_name': 'efficientnet_b0', # Model architecture\n        'dropout_rate': 0.286      # Dropout rate\n    }\n\n    # Create configuration with manual parameters\n    config = config_class()\n    config.lr = BEST_PARAMS['lr']\n    config.batch_size = BEST_PARAMS['batch_size']\n    config.weight_decay = BEST_PARAMS['weight_decay']\n    config.model_name = BEST_PARAMS['model_name']\n    config.dropout_rate = BEST_PARAMS['dropout_rate']\n\n    # Prepare data\n    trainer = ModelTrainer(config)\n    train_df, val_df = trainer.prepare_data(data_dir)\n    \n    # Create data loaders\n    train_loader, val_loader = trainer.create_dataloaders(train_df, val_df)\n    \n    # Train model with best configuration\n    model, predictions, labels, history = trainer.train(train_loader, val_loader)\n    \n    # Visualization\n    visualizer = ModelVisualizer()\n    \n    # 1. Training History Plot\n    visualizer.plot_training_history(history)\n    \n    # 2. Confusion Matrix (pass class names explicitly)\n    visualizer.plot_confusion_matrix(labels, predictions, CLASS_NAMES)\n    \n    # 3. ROC Curves (pass class names explicitly)\n    visualizer.plot_roc_curve(labels, predictions, CLASS_NAMES)\n    \n    # 4. Save Best Model with Additional Metadata\n    model_save_path = 'best_model_full.pth'\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'best_config': BEST_PARAMS,\n        'class_names': CLASS_NAMES,\n        'training_history': history\n    }, model_save_path)\n    \n    \n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T13:50:43.832718Z","iopub.execute_input":"2025-03-29T13:50:43.833126Z","iopub.status.idle":"2025-03-29T14:00:07.416449Z","shell.execute_reply.started":"2025-03-29T13:50:43.833093Z","shell.execute_reply":"2025-03-29T14:00:07.415611Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 0.9165\nVal Loss: 0.7633\nVal AUC: 0.8667\nEpoch 2/10\nTrain Loss: 0.5824\nVal Loss: 0.5417\nVal AUC: 0.9323\nEpoch 3/10\nTrain Loss: 0.4247\nVal Loss: 0.4203\nVal AUC: 0.9517\nEpoch 4/10\nTrain Loss: 0.3409\nVal Loss: 0.3521\nVal AUC: 0.9646\nEpoch 5/10\nTrain Loss: 0.2768\nVal Loss: 0.2951\nVal AUC: 0.9742\nEpoch 6/10\nTrain Loss: 0.2369\nVal Loss: 0.3264\nVal AUC: 0.9748\nEpoch 7/10\nTrain Loss: 0.2068\nVal Loss: 0.3187\nVal AUC: 0.9757\nEpoch 8/10\nTrain Loss: 0.1837\nVal Loss: 0.2549\nVal AUC: 0.9807\nEpoch 9/10\nTrain Loss: 0.1591\nVal Loss: 0.2748\nVal AUC: 0.9799\nEpoch 10/10\nTrain Loss: 0.1387\nVal Loss: 0.2762\nVal AUC: 0.9825\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}